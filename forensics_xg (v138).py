# -*- coding: utf-8 -*-
"""Forensics xG.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HXahst9EouNaxkFii2bNbwgR_lbGrts5
"""

!pkill -f streamlit
!pkill -f localtunnel
!pkill -f cloudflared
import os
import shutil

# Wipe cache and config to ensure clean speed test
if os.path.exists(".streamlit"):
    shutil.rmtree(".streamlit")

print("‚úÖ Cache cleared. Engines ready.")

# Commented out IPython magic to ensure Python compatibility.
# %%writefile forensics_app.py
# import streamlit as st
# import pandas as pd
# import numpy as np
# import json
# import requests
# from mplsoccer import Pitch
# import plotly.express as px
# from io import BytesIO
# from urllib.parse import quote
# import matplotlib.pyplot as plt
# import os
# 
# # --- 1. CONFIGURATION (Native Dark Mode) ---
# # This forces the app to be Dark Mode without heavy CSS hacking.
# os.makedirs(".streamlit", exist_ok=True)
# with open(".streamlit/config.toml", "w") as f:
#     f.write("""
# [theme]
# base="dark"
# primaryColor="#ff4b4b"
# backgroundColor="#0e1117"
# secondaryBackgroundColor="#262730"
# textColor="#fafafa"
# font="sans serif"
# [server]
# headless = true
# """)
# 
# # --- 2. SETUP ---
# st.set_page_config(page_title="Forensics xG", layout="wide", page_icon="üß¨")
# 
# # --- 3. OPTIMIZED DATA LOADER (The Speed Fix) ---
# GITHUB_BASE = "https://raw.githubusercontent.com/jczpineda/Forensics-xG/main/"
# 
# @st.cache_data(show_spinner=False)
# def load_stats_data(path_or_url):
#     """
#     Fetches AND processes statistics data.
#     Converting to numeric happens ONCE here, not in the UI loop.
#     """
#     if path_or_url.startswith("http"):
#         url = path_or_url.replace("github.com", "raw.githubusercontent.com").replace("/blob/", "/")
#     else:
#         safe_path = quote(path_or_url)
#         url = GITHUB_BASE + safe_path
# 
#     try:
#         r = requests.get(url)
#         if r.status_code != 200:
#             return None, f"HTTP {r.status_code}"
# 
#         # Load Data
#         if url.lower().endswith('.csv'):
#             df = pd.read_csv(BytesIO(r.content))
#         else:
#             df = pd.read_excel(BytesIO(r.content), engine='openpyxl')
# 
#         # Clean Data (Heavy lifting done once)
#         df.columns = df.columns.astype(str).str.strip()
# 
#         # Pre-calculate Per 90s if possible
#         has_90s = '90s' in df.columns
#         if has_90s:
#             # Create a copy for Per 90 stats
#             # We store it in the same DF with a suffix or just return raw for now
#             # To keep it simple and fast, we just clean numerics here
#             pass
# 
#         # Force convert all numeric-looking columns
#         for col in df.columns:
#             df[col] = pd.to_numeric(df[col], errors='ignore')
# 
#         return df, None
#     except Exception as e:
#         return None, str(e)
# 
# @st.cache_data(show_spinner=False)
# def load_match_data(path_or_url):
#     """
#     Fetches AND parses JSON match data.
#     The heavy parsing loop happens ONCE here.
#     """
#     if path_or_url.startswith("http"):
#         url = path_or_url.replace("github.com", "raw.githubusercontent.com").replace("/blob/", "/")
#     else:
#         safe_path = quote(path_or_url)
#         url = GITHUB_BASE + safe_path
# 
#     try:
#         r = requests.get(url)
#         if r.status_code != 200:
#             return None, f"HTTP {r.status_code}"
# 
#         # Fix potential JSON formatting issues
#         text = r.content.decode('utf-8', errors='ignore')
#         s, e = text.find('('), text.rfind(')')
#         if s != -1 and e != -1:
#             json_data = json.loads(text[s+1:e])
#         else:
#             s, e = text.find('{'), text.rfind('}')
#             if s != -1 and e != -1:
#                 json_data = json.loads(text[s:e+1])
#             else:
#                 return None, "Invalid JSON format"
# 
#         # PARSE EVENTS (The Slow Part)
#         events = []
#         try:
#             try:
#                 contestants = json_data['matchInfo']['contestant']
#                 home_name, home_id = contestants[0]['name'], contestants[0]['id']
#                 away_name = contestants[1]['name']
#             except: home_name, away_name, home_id = "Home", "Away", "Unknown"
# 
#             raw = json_data.get('liveData', {}).get('event', [])
#             if not raw: raw = json_data.get('event', [])
# 
#             for ev in raw:
#                 try:
#                     events.append({
#                         "Type": int(ev.get('typeId', 0)), # Force int
#                         "Player": ev.get('playerName', 'Unknown'),
#                         "Team": home_name if ev.get('contestantId') == home_id else away_name,
#                         "Period": ev.get('periodId'),
#                         "x": float(ev.get('x', 0)),
#                         "y": float(ev.get('y', 0)),
#                         "endX": float(next((q['value'] for q in ev.get('qualifier', []) if q['qualifierId']==140), ev.get('x', 0))),
#                         "endY": float(next((q['value'] for q in ev.get('qualifier', []) if q['qualifierId']==141), ev.get('y', 0))),
#                         "Outcome": "Successful" if ev.get('outcome')==1 else "Unsuccessful"
#                     })
#                 except: continue
#         except Exception as e:
#             return None, f"Parse Error: {str(e)}"
# 
#         return pd.DataFrame(events), None
# 
#     except Exception as e:
#         return None, str(e)
# 
# # --- 4. DATA INDEX ---
# CASE_DATABASE = {
#     "RUBEN AMORIM": {
#         "json_files": {
#             "vs Arsenal": "amorim.json/Arsenal.JSON",
#             "vs Aston Villa": "amorim.json/Aston Villa.JSON",
#             "vs Bournemouth": "amorim.json/Bournemouth.JSON",
#             "vs Brentford": "amorim.json/Brentford.JSON",
#             "vs Brighton": "amorim.json/Brighton.JSON",
#             "vs Burnley": "amorim.json/Burnley.JSON",
#             "vs Chelsea": "amorim.json/Chelsea.JSON",
#             "vs Crystal Palace": "amorim.json/Crystal Palace.JSON",
#             "vs Everton": "amorim.json/Everton.JSON",
#             "vs Fulham": "amorim.json/Fulham.JSON",
#             "vs Leeds United": "amorim.json/Leeds United.JSON",
#             "vs Liverpool": "amorim.json/Liverpool.JSON",
#             "vs Manchester City": "amorim.json/Manchester City.JSON",
#             "vs Newcastle United": "amorim.json/Newcastle United.JSON",
#             "vs Nottingham Forest": "amorim.json/Nottingham.JSON",
#             "vs Sunderland": "amorim.json/Sunderland.JSON",
#             "vs Tottenham": "amorim.json/Tottenham.JSON",
#             "vs West Ham": "amorim.json/West Ham.JSON",
#             "vs Wolverhampton": "amorim.json/Wolverhampton.JSON",
#             "vs Wolverhampton (2)": "amorim.json/Wolverhampton 2.JSON"
#         },
#         "stats_files": {
#             "üß§ GK Advanced (Against)": "amorim.csv/Advanced Goalkeeper Stats Against (2025-2026).xlsx",
#             "üß§ GK Advanced (For)": "amorim.csv/Advanced Goalkeeper Stats For (2025-2026).xlsx",
#             "üß§ GK Standard (Against)": "amorim.csv/Goalkeeper Stats Against (2025-2026).xlsx",
#             "üß§ GK Standard (For)": "amorim.csv/Goalkeeper Stats For (2025-2026).xlsx",
#             "üéØ Shooting (Against)": "amorim.csv/Shooting Against (2025-2026).xlsx",
#             "üéØ Shooting (For)": "amorim.csv/Shooting For (2025-2026).xlsx",
#             "‚ö° Goal/Shot Creation (Against)": "amorim.csv/Squad Goal and Shot Creation Against (2025-2026).xlsx",
#             "‚ö° Goal/Shot Creation (For)": "amorim.csv/Squad Goal and Shot Creation For (2025-2026).xlsx",
#             "‚öΩ Passing (Against)": "amorim.csv/Passing Against (2025-2026).xlsx",
#             "‚öΩ Passing (For)": "amorim.csv/Passing For (2025-2026).xlsx",
#             "üß† Passing Types (Against)": "amorim.csv/Passing Types Against (2025-2026).xlsx",
#             "üß† Passing Types (For)": "amorim.csv/Passing Types For (2025-2026).xlsx",
#             "‚è≥ Possession (Against)": "amorim.csv/Possession Against (2025-2026).xlsx",
#             "‚è≥ Possession (For)": "amorim.csv/Possession For (2025-2026).xlsx",
#             "üõ°Ô∏è Squad Defense (Against)": "amorim.csv/Squad Defense Against (2025-2026).xlsx",
#             "üõ°Ô∏è Squad Defense (For)": "amorim.csv/Squad Defense For (2025-2026).xlsx",
#             "üèÜ Overall Results": "amorim.csv/Overall Results (2025-2026).xlsx",
#             "üè† Home/Away Results": "amorim.csv/Home-Away Results (2025-2026).xlsx",
#             "‚è±Ô∏è Playing Time (Against)": "amorim.csv/Playing Time Against (2025-2026).xlsx",
#             "‚è±Ô∏è Playing Time (For)": "amorim.csv/Playing Time For (2025-2026).xlsx",
#             "üìä Standard Stats (Against)": "amorim.csv/Standard Stats Against (2025-2026).xlsx",
#             "üìä Standard Stats (For)": "amorim.csv/Standard Stats For (2025-2026).xlsx",
#             "üß© Misc Stats (Against)": "amorim.csv/Miscellaneous Stats Against (2025-2026).xlsx",
#             "üß© Misc Stats (For)": "amorim.csv/Miscellaneous Stats For (2025-2026).xlsx",
#         }
#     },
#     "DARREN FLETCHER": {
#         "json_files": { "vs Burnley (2)": "fletcher.json/Burnley 2.JSON" },
#         "stats_files": {}
#     },
#     "MICHAEL CARRICK": {
#         "json_files": { "vs Arsenal (2)": "carrick.json/Arsenal 2.JSON", "vs Manchester City (2)": "carrick.json/Manchester City 2.JSON" },
#         "stats_files": {}
#     }
# }
# 
# # --- 5. INTERFACE ---
# st.markdown("""
#     <style>
#     /* Minimal tweaks to standard Dark Mode */
#     .tagline {
#         font-size: 24px !important;
#         font-weight: 700 !important;
#         color: #a3a8b8 !important;
#         margin-top: -20px !important;
#         margin-bottom: 30px !important;
#     }
#     header {visibility: hidden;}
#     </style>
# """, unsafe_allow_html=True)
# 
# # Title Area
# c1, c2 = st.columns([1, 8])
# with c1:
#     st.markdown("# üß¨")
# with c2:
#     st.title("FORENSICS xG | CRIME SCENE INVESTIGATION")
#     st.markdown('<div class="tagline">Where the Beautiful Game Meets Hard Evidence</div>', unsafe_allow_html=True)
# 
# st.divider()
# st.subheader("SELECT SUSPECT")
# 
# managers = list(CASE_DATABASE.keys())
# tabs = st.tabs(managers)
# 
# for i, manager in enumerate(managers):
#     with tabs[i]:
#         sub_t1, sub_t2 = st.tabs(["üìä STATISTICAL REPORTS", "‚öΩ MATCH TELEMETRY"])
# 
#         # === TAB A: STATS ===
#         with sub_t1:
#             files = CASE_DATABASE[manager]["stats_files"]
#             options = list(files.keys())
#             selected_option = st.selectbox("Select Evidence File", options, key=f"s_{manager}")
#             target_path = files.get(selected_option, "")
# 
#             if target_path:
#                 # FAST LOADING FROM CACHE
#                 df, err = load_stats_data(target_path)
# 
#                 if df is not None:
#                     # Per 90 Logic (Fast, in-memory)
#                     has_90s = '90s' in df.columns
#                     c_toggle, _ = st.columns([2, 4])
#                     use_per_90 = False
#                     if has_90s:
#                         use_per_90 = c_toggle.toggle("‚öñÔ∏è Normalize Per 90", key=f"p90_{manager}")
# 
#                     # Prepare display dataframe
#                     display_df = df.copy()
#                     if use_per_90:
#                         num_cols = display_df.select_dtypes(include=np.number).columns
#                         for col in num_cols:
#                             if col not in ['90s', 'Year', 'Age', 'Season']:
#                                 display_df[col] = (display_df[col] / display_df['90s']).round(2)
# 
#                     # Controls
#                     all_cols = display_df.columns.tolist()
#                     num_cols = display_df.select_dtypes(include=np.number).columns.tolist()
# 
#                     if all_cols:
#                         c1, c2, c3 = st.columns(3)
#                         x = c1.selectbox("X Axis", all_cols, index=0, key=f"sx_{manager}")
#                         y = c2.selectbox("Y Axis", num_cols if num_cols else all_cols, index=1 if len(num_cols)>1 else 0, key=f"sy_{manager}")
#                         lbl = c3.selectbox("Label", all_cols, index=0, key=f"sl_{manager}")
# 
#                         # Plot
#                         if y in num_cols:
#                             fig = px.scatter(display_df, x=x, y=y, text=lbl, template="plotly_dark")
#                             fig.update_traces(marker=dict(size=12, color='#ff4b4b', line=dict(width=1, color='white')), textposition='top center')
#                             fig.update_layout(height=500, plot_bgcolor='#0e1117', paper_bgcolor='#0e1117')
#                             st.plotly_chart(fig, use_container_width=True)
#                         else:
#                             st.warning("Y-Axis must be numeric for a scatter plot.")
# 
#                         st.divider()
#                         st.dataframe(display_df, use_container_width=True)
#                 else:
#                     st.error(f"Error loading file: {err}")
# 
#         # === TAB B: TELEMETRY ===
#         with sub_t2:
#             files = CASE_DATABASE[manager]["json_files"]
#             options = list(files.keys())
# 
#             if options:
#                 selected_match = st.selectbox("Select Match", options, key=f"m_{manager}")
#                 target_path = files.get(selected_match, "")
# 
#                 if target_path:
#                     # FAST LOADING FROM CACHE
#                     with st.spinner("Analyzing Match Data..."):
#                         match_df, err = load_match_data(target_path)
# 
#                     if match_df is not None and not match_df.empty:
#                         teams = match_df['Team'].unique()
#                         st.header(f"{teams[0]} vs {teams[1]}")
# 
#                         c1, c2, c3 = st.columns(3)
#                         sel_team = c1.selectbox("Squad", teams, key=f"st_{manager}")
# 
#                         team_players = sorted(match_df[match_df['Team']==sel_team]['Player'].unique())
#                         team_players.insert(0, "All Players")
#                         sel_player = c2.selectbox("Player", team_players, key=f"sp_{manager}")
# 
#                         sel_period = c3.selectbox("Period", ["Full Match", "1st Half", "2nd Half"], key=f"sper_{manager}")
# 
#                         # Filter (Fast in-memory)
#                         plot_df = match_df[match_df['Team'] == sel_team]
#                         if sel_period == "1st Half": plot_df = plot_df[plot_df['Period'] == 1]
#                         elif sel_period == "2nd Half": plot_df = plot_df[plot_df['Period'] == 2]
#                         if sel_player != "All Players": plot_df = plot_df[plot_df['Player'] == sel_player]
# 
#                         modules = st.multiselect("Layers", ["Pass Map", "Heatmap", "Avg Positions"], default=["Pass Map"], key=f"mod_{manager}")
# 
#                         # Plot Pitch
#                         fig, ax = plt.subplots(figsize=(10, 7))
#                         fig.set_facecolor('#0e1117')
#                         ax.set_facecolor('#0e1117')
#                         pitch = Pitch(pitch_type='opta', pitch_color='#0e1117', line_color='white')
#                         pitch.draw(ax=ax)
# 
#                         if "Pass Map" in modules:
#                             passes = plot_df[plot_df['Type'] == 1]
#                             if not passes.empty:
#                                 succ = passes[passes['Outcome'] == 'Successful']
#                                 fail = passes[passes['Outcome'] == 'Unsuccessful']
#                                 pitch.arrows(succ.x, succ.y, succ.endX, succ.endY, width=2, color='#00ff85', alpha=0.6, ax=ax)
#                                 pitch.arrows(fail.x, fail.y, fail.endX, fail.endY, width=2, color='#ff4b4b', alpha=0.6, ax=ax)
# 
#                         if "Heatmap" in modules and not plot_df.empty:
#                             pitch.kdeplot(plot_df.x, plot_df.y, ax=ax, cmap='hot', fill=True, levels=100, alpha=0.6)
# 
#                         if "Avg Positions" in modules and not plot_df.empty:
#                             avg = plot_df.groupby('Player')[['x', 'y']].mean().reset_index()
#                             pitch.scatter(avg.x, avg.y, s=300, color='white', edgecolors='black', ax=ax)
#                             for _, r in avg.iterrows():
#                                 pitch.annotate(r.Player.split(" ")[-1], xy=(r.x, r.y), c='white', va='center', ha='center', size=8, ax=ax)
# 
#                         st.pyplot(fig)
#                         plt.close(fig)
#                     else:
#                         st.error(f"Error parsing match data: {err}")

!streamlit run forensics_app.py &>/dev/null &
!./cloudflared-linux-amd64 tunnel --url http://localhost:8501