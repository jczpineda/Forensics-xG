# -*- coding: utf-8 -*-
"""Forensics xG.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HXahst9EouNaxkFii2bNbwgR_lbGrts5
"""

!wget -q -O - ipv4.icanhazip.com

# Commented out IPython magic to ensure Python compatibility.
# %%writefile forensics_app.py
# import streamlit as st
# import pandas as pd
# import numpy as np
# import json
# import requests
# from mplsoccer import Pitch
# import plotly.express as px
# from io import BytesIO
# from urllib.parse import quote
# from datetime import datetime
# import matplotlib.pyplot as plt
# import os
# 
# # --- 1. CONFIGURATION (FORCE VISIBILITY) ---
# # We recreate the config to lock the app in "Light Mode" (White Background / Black Text).
# # This guarantees the Data Table is visible.
# os.makedirs(".streamlit", exist_ok=True)
# with open(".streamlit/config.toml", "w") as f:
#     f.write("""
# [theme]
# base="light"
# primaryColor="#ff4b4b"
# backgroundColor="#ffffff"
# secondaryBackgroundColor="#f0f2f6"
# textColor="#000000"
# font="sans serif"
# [server]
# headless = true
# """)
# 
# # --- 2. SETUP ---
# st.set_page_config(page_title="Forensics xG", layout="wide", page_icon="ðŸ§¬")
# plt.style.use('default')
# 
# # --- 3. CSS PATCH ---
# st.markdown("""
#     <style>
#     /* High visibility border for dropdowns */
#     div[data-baseweb="select"] > div {
#         border: 1px solid #ff4b4b !important;
#         background-color: white !important;
#         color: black !important;
#     }
#     </style>
# """, unsafe_allow_html=True)
# 
# # --- 4. DATA ENGINE ---
# CASE_DATABASE = {
#     "RUBEN AMORIM": {
#         "json_files": {
#             "vs Arsenal": "amorim.json/Arsenal.JSON",
#             "vs Aston Villa": "amorim.json/Aston Villa.JSON",
#             "vs Bournemouth": "amorim.json/Bournemouth.JSON",
#             "vs Brentford": "amorim.json/Brentford.JSON",
#             "vs Brighton": "amorim.json/Brighton.JSON",
#             "vs Burnley": "amorim.json/Burnley.JSON",
#             "vs Chelsea": "amorim.json/Chelsea.JSON",
#             "vs Crystal Palace": "amorim.json/Crystal Palace.JSON",
#             "vs Everton": "amorim.json/Everton.JSON",
#             "vs Fulham": "amorim.json/Fulham.JSON",
#             "vs Leeds United": "amorim.json/Leeds United.JSON",
#             "vs Liverpool": "amorim.json/Liverpool.JSON",
#             "vs Manchester City": "amorim.json/Manchester City.JSON",
#             "vs Newcastle United": "amorim.json/Newcastle United.JSON",
#             "vs Nottingham Forest": "amorim.json/Nottingham.JSON",
#             "vs Sunderland": "amorim.json/Sunderland.JSON",
#             "vs Tottenham": "amorim.json/Tottenham.JSON",
#             "vs West Ham": "amorim.json/West Ham.JSON",
#             "vs Wolverhampton": "amorim.json/Wolverhampton.JSON",
#             "vs Wolverhampton (2)": "amorim.json/Wolverhampton 2.JSON"
#         },
#         "stats_files": {
#             "ðŸ§¤ GK Advanced (Against)": "amorim.csv/Advanced Goalkeeper Stats Against (2025-2026).xlsx",
#             "ðŸ§¤ GK Advanced (For)": "amorim.csv/Advanced Goalkeeper Stats For (2025-2026).xlsx",
#             "ðŸ§¤ GK Standard (Against)": "amorim.csv/Goalkeeper Stats Against (2025-2026).xlsx",
#             "ðŸ§¤ GK Standard (For)": "amorim.csv/Goalkeeper Stats For (2025-2026).xlsx",
#             "ðŸŽ¯ Shooting (Against)": "amorim.csv/Shooting Against (2025-2026).xlsx",
#             "ðŸŽ¯ Shooting (For)": "amorim.csv/Shooting For (2025-2026).xlsx",
#             "âš¡ Goal/Shot Creation (Against)": "amorim.csv/Squad Goal and Shot Creation Against (2025-2026).xlsx",
#             "âš¡ Goal/Shot Creation (For)": "amorim.csv/Squad Goal and Shot Creation For (2025-2026).xlsx",
#             "âš½ Passing (Against)": "amorim.csv/Passing Against (2025-2026).xlsx",
#             "âš½ Passing (For)": "amorim.csv/Passing For (2025-2026).xlsx",
#             "ðŸ§  Passing Types (Against)": "amorim.csv/Passing Types Against (2025-2026).xlsx",
#             "ðŸ§  Passing Types (For)": "amorim.csv/Passing Types For (2025-2026).xlsx",
#             "â³ Possession (Against)": "amorim.csv/Possession Against (2025-2026).xlsx",
#             "â³ Possession (For)": "amorim.csv/Possession For (2025-2026).xlsx",
#             "ðŸ›¡ï¸ Squad Defense (Against)": "amorim.csv/Squad Defense Against (2025-2026).xlsx",
#             "ðŸ›¡ï¸ Squad Defense (For)": "amorim.csv/Squad Defense For (2025-2026).xlsx",
#             "ðŸ† Overall Results": "amorim.csv/Overall Results (2025-2026).xlsx",
#             "ðŸ  Home/Away Results": "amorim.csv/Home-Away Results (2025-2026).xlsx",
#             "â±ï¸ Playing Time (Against)": "amorim.csv/Playing Time Against (2025-2026).xlsx",
#             "â±ï¸ Playing Time (For)": "amorim.csv/Playing Time For (2025-2026).xlsx",
#             "ðŸ“Š Standard Stats (Against)": "amorim.csv/Standard Stats Against (2025-2026).xlsx",
#             "ðŸ“Š Standard Stats (For)": "amorim.csv/Standard Stats For (2025-2026).xlsx",
#             "ðŸ§© Misc Stats (Against)": "amorim.csv/Miscellaneous Stats Against (2025-2026).xlsx",
#             "ðŸ§© Misc Stats (For)": "amorim.csv/Miscellaneous Stats For (2025-2026).xlsx",
#         }
#     },
#     "DARREN FLETCHER": {
#         "json_files": { "vs Burnley (2)": "fletcher.json/Burnley 2.JSON" },
#         "stats_files": {}
#     },
#     "MICHAEL CARRICK": {
#         "json_files": { "vs Arsenal (2)": "carrick.json/Arsenal 2.JSON", "vs Manchester City (2)": "carrick.json/Manchester City 2.JSON" },
#         "stats_files": {}
#     }
# }
# 
# GITHUB_BASE = "https://raw.githubusercontent.com/jczpineda/Forensics-xG/main/"
# 
# @st.cache_data(show_spinner=False)
# def fetch_smart(path_or_url, file_type):
#     if path_or_url.startswith("http"):
#         url = path_or_url.replace("github.com", "raw.githubusercontent.com").replace("/blob/", "/")
#     else:
#         safe_path = quote(path_or_url)
#         url = GITHUB_BASE + safe_path
# 
#     try:
#         r = requests.get(url)
#         if r.status_code == 200:
#             if file_type == 'json' or url.lower().endswith('.json'):
#                 text = r.content.decode('utf-8', errors='ignore')
#                 s, e = text.find('('), text.rfind(')')
#                 if s!=-1 and e!=-1: return True, json.loads(text[s+1:e]), url
#                 s, e = text.find('{'), text.rfind('}')
#                 if s!=-1 and e!=-1: return True, json.loads(text[s:e+1]), url
#                 return False, "JSON Clean Failed", url
#             elif url.lower().endswith('.csv'):
#                 return True, pd.read_csv(BytesIO(r.content)), url
#             else:
#                 return True, pd.read_excel(BytesIO(r.content), engine='openpyxl'), url
#         return False, f"HTTP {r.status_code}", url
#     except Exception as e:
#         return False, str(e), url
# 
# def parse_match_events(json_data):
#     events = []
#     try:
#         try:
#             contestants = json_data['matchInfo']['contestant']
#             home_name, home_id = contestants[0]['name'], contestants[0]['id']
#             away_name = contestants[1]['name']
#         except: home_name, away_name, home_id = "Home", "Away", "Unknown"
# 
#         raw = json_data.get('liveData', {}).get('event', [])
#         if not raw: raw = json_data.get('event', [])
# 
#         for e in raw:
#             try:
#                 tid = e.get('typeId')
#                 events.append({
#                     "Type": tid,
#                     "Player": e.get('playerName', 'Unknown'),
#                     "Team": home_name if e.get('contestantId') == home_id else away_name,
#                     "Period": e.get('periodId'),
#                     "x": float(e.get('x', 0)),
#                     "y": float(e.get('y', 0)),
#                     "endX": float(next((q['value'] for q in e.get('qualifier', []) if q['qualifierId']==140), e.get('x', 0))),
#                     "endY": float(next((q['value'] for q in e.get('qualifier', []) if q['qualifierId']==141), e.get('y', 0))),
#                     "Outcome": "Successful" if e.get('outcome')==1 else "Unsuccessful"
#                 })
#             except: continue
#     except: return pd.DataFrame()
#     return pd.DataFrame(events)
# 
# # --- 5. INTERFACE ---
# with st.sidebar:
#     st.header("ðŸ§¬ FORENSICS UNIT")
#     st.divider()
# 
#     # Placeholder for Sidebar Logo
#     st.image("https://placehold.co/400x150?text=LOGO", use_container_width=True)
# 
#     st.divider()
#     app_mode = st.radio("SELECT MODULE", ["CRIME SCENE", "INTELLIGENCE UNIT"])
# 
#     st.divider()
#     st.markdown("### SYSTEM METRICS")
#     st.info("SIGNAL: STRONG ðŸŸ¢")
#     st.info("LEVEL: 5")
#     st.caption(f"Date: {datetime.now().strftime('%Y-%m-%d')}")
# 
# if app_mode == "CRIME SCENE":
#     # Placeholder for Main Banner
#     st.image("https://placehold.co/1200x200?text=FORENSICS+xG+DATABASE", use_container_width=True)
# 
#     st.title("FORENSICS xG")
#     st.write("TACTICAL INTELLIGENCE DIVISION")
#     st.divider()
#     st.subheader("SELECT SUSPECT")
# 
#     managers = list(CASE_DATABASE.keys())
#     tabs = st.tabs(managers)
# 
#     for i, manager in enumerate(managers):
#         with tabs[i]:
#             sub_t1, sub_t2 = st.tabs(["ðŸ“Š STATISTICAL REPORTS", "âš½ MATCH TELEMETRY"])
# 
#             # === TAB A: STATS ===
#             with sub_t1:
#                 st.info("â„¹ï¸ Select a file below to generate the analysis.")
#                 files = CASE_DATABASE[manager]["stats_files"]
#                 options = list(files.keys())
#                 selected_option = st.selectbox("Select Evidence File", options, key=f"s_sel_{i}")
#                 target_path = files.get(selected_option, "")
# 
#                 if target_path:
#                     success, result, final_url = fetch_smart(target_path, 'excel')
#                     if success:
#                         st.success(f"âœ… File Loaded Successfully: {selected_option}")
#                         df = result
#                         df.columns = df.columns.astype(str).str.strip()
# 
#                         # FIX: Correctly converting data for display
#                         for col in df.columns:
#                             df[col] = pd.to_numeric(df[col], errors='ignore')
# 
#                         num_cols = df.select_dtypes(include=np.number).columns.tolist()
#                         txt_cols = df.select_dtypes(include='object').columns.tolist()
# 
#                         if num_cols:
#                             c1, c2, c3 = st.columns(3)
#                             x = c1.selectbox("X Axis", num_cols, index=0, key=f"sx_{i}")
#                             y = c2.selectbox("Y Axis", num_cols, index=1 if len(num_cols)>1 else 0, key=f"sy_{i}")
#                             lbl = c3.selectbox("Label", txt_cols, index=0 if txt_cols else None, key=f"sl_{i}")
# 
#                             plot_df = df.copy()
#                             plot_df[x] = pd.to_numeric(plot_df[x], errors='coerce')
#                             plot_df[y] = pd.to_numeric(plot_df[y], errors='coerce')
#                             plot_df = plot_df.dropna(subset=[x, y])
# 
#                             if not plot_df.empty:
#                                 st.subheader(f"ðŸ“ˆ Analysis: {x} vs {y}")
#                                 fig = px.scatter(plot_df, x=x, y=y, text=lbl, template="plotly_white")
#                                 fig.update_traces(marker=dict(size=14, color='#ff4b4b', line=dict(width=1, color='black')), textposition='top center')
#                                 fig.update_layout(height=600)
#                                 st.plotly_chart(fig, use_container_width=True)
#                             else: st.warning("âš ï¸ No valid numeric data found for these columns.")
# 
#                             st.divider()
#                             st.subheader("ðŸ“‚ Raw Evidence Data")
#                             # Explicitly using dataframe with full width
#                             st.dataframe(df, use_container_width=True)
#                         else: st.warning("âš ï¸ This file contains no numeric columns to plot.")
#                     else: st.error(f"âŒ Connection Failed: {result}")
#                 else: st.info("No Stats Files available.")
# 
#             # === TAB B: TELEMETRY ===
#             with sub_t2:
#                 st.info("â„¹ï¸ Match Telemetry.")
#                 files = CASE_DATABASE[manager]["json_files"]
#                 options = list(files.keys())
# 
#                 if options:
#                     selected_option = st.selectbox("Select Match Report", options, key=f"j_sel_{i}")
#                     target_path = files.get(selected_option, "")
# 
#                     if target_path:
#                         with st.spinner("Decrypting Match Data..."):
#                             success, result, final_url = fetch_smart(target_path, 'json')
# 
#                         if success:
#                             st.success(f"âœ… Match Data Loaded")
#                             df = parse_match_events(result)
#                             if not df.empty:
#                                 teams = df['Team'].unique()
#                                 st.header(f"{teams[0]} vs {teams[1]}")
# 
#                                 c1, c2, c3 = st.columns(3)
#                                 team = c1.selectbox("Squad", teams, key=f"tm_{i}")
#                                 players = sorted(df[df['Team']==team]['Player'].unique())
#                                 players.insert(0, "All Players")
#                                 player = c2.selectbox("Player", players, key=f"pl_{i}")
#                                 period = c3.selectbox("Period", ["Full Match", "1st Half", "2nd Half"], key=f"per_{i}")
# 
#                                 plot_df = df[df['Team']==team].copy()
#                                 if period == "1st Half": plot_df = plot_df[plot_df['Period'] == 1]
#                                 elif period == "2nd Half": plot_df = plot_df[plot_df['Period'] == 2]
#                                 if player != "All Players": plot_df = plot_df[plot_df['Player'] == player]
# 
#                                 st.divider()
#                                 modules = st.multiselect("Visualization Layers", ["Pass Map", "Heatmap", "Avg Positions"], default=["Pass Map"], key=f"mod_{i}")
# 
#                                 fig, ax = plt.subplots(figsize=(10, 7))
#                                 pitch = Pitch(pitch_type='opta', pitch_color='white', line_color='black')
#                                 pitch.draw(ax=ax)
# 
#                                 if "Pass Map" in modules:
#                                     passes = plot_df[plot_df['Type'] == 1]
#                                     if not passes.empty:
#                                         succ = len(passes[passes['Outcome'] == 'Successful'])
#                                         fail = len(passes[passes['Outcome'] == 'Unsuccessful'])
#                                         acc = round((succ/(succ+fail))*100, 1) if (succ+fail) > 0 else 0
#                                         st.caption(f"Pass Accuracy: {acc}% ({succ}/{succ+fail})")
# 
#                                         succ_p = passes[passes['Outcome'] == 'Successful']
#                                         fail_p = passes[passes['Outcome'] == 'Unsuccessful']
#                                         pitch.arrows(succ_p.x, succ_p.y, succ_p.endX, succ_p.endY, width=2, color='green', alpha=0.6, ax=ax)
#                                         pitch.arrows(fail_p.x, fail_p.y, fail_p.endX, fail_p.endY, width=2, color='red', alpha=0.6, ax=ax)
# 
#                                 if "Heatmap" in modules:
#                                     if not plot_df.empty:
#                                         pitch.kdeplot(plot_df.x, plot_df.y, ax=ax, cmap='Reds', fill=True, levels=100, alpha=0.7)
# 
#                                 if "Avg Positions" in modules:
#                                     pass_df = plot_df[plot_df['Type'] == 1]
#                                     if not pass_df.empty:
#                                         avg = pass_df.groupby('Player')[['x', 'y']].mean().reset_index()
#                                         pitch.scatter(avg.x, avg.y, s=300, color='blue', edgecolors='black', alpha=0.6, ax=ax)
#                                         for _, row in avg.iterrows():
#                                             pitch.annotate(row.Player.split(" ")[-1], xy=(row.x, row.y), c='black', va='center', ha='center', size=8, ax=ax)
#                                 st.pyplot(fig)
#                                 plt.close(fig)
#                         else: st.error(result)
#                 else: st.info(f"No Match Telemetry available.")
# 
# elif app_mode == "INTELLIGENCE UNIT":
#     st.info("Access Denied.")

!pkill -f localtunnel
!streamlit run forensics_app.py & npx localtunnel --port 8501